{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Exercise, now with hyperparameter tuning via Cloud ML Engine \n",
    "\n",
    "Create a neural network that is capable of finding the volume of a cylinder given the radius of its base (r) and its height (h). Assume that the radius and height of the cylinder are both in the range 0.5 to 2.0. Unlike in the challenge exercise for b_estimator.ipynb, assume that your measurements of r, h and V are all rounded off to the nearest 0.1. Simulate the necessary training dataset. This time, you will need a lot more data to get a good predictor.\n",
    "<p>\n",
    "Now modify the \"noise\" so that instead of just rounding off the value, there is up to a 10% error (uniformly distributed) in the measurement followed by rounding off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'cylinders'\n",
    "BUCKET = 'cylinders'\n",
    "REGION = 'europe-west1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bash\n",
    "import os\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = '1.8'  # Tensorflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate cylinders and upload to bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 8000 cylinders to cylinders_train.csv\n",
      "saved 1000 cylinders to cylinders_eval.csv\n",
      "saved 1000 cylinders to cylinders_test.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Generate cylinders and upload to bucket\n",
    "python generate_cylinders.py --filename \"cylinders_train.csv\" --size 8000\n",
    "python generate_cylinders.py --filename \"cylinders_eval.csv\" --size 1000\n",
    "python generate_cylinders.py --filename \"cylinders_test.csv\" --size 1000\n",
    "# gsutil mv \"cylinders_*.csv\" \"gs://$BUCKET/input/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create command-line program\n",
    "\n",
    "In order to submit to Cloud ML Engine, we need to create a distributed training program. Let's convert our housing example to fit that paradigm, using the Estimators API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf cylinder_prediction_module\n",
    "mkdir cylinder_prediction_module\n",
    "mkdir cylinder_prediction_module/trainer\n",
    "touch cylinder_prediction_module/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### task.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cylinder_prediction_module/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cylinder_prediction_module/trainer/task.py\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "from . import model\n",
    "    \n",
    "if __name__ == '__main__' and 'get_ipython' not in dir():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--learning_rate',\n",
    "        type = float, \n",
    "        default = 0.01\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--batch_size',\n",
    "        type = int, \n",
    "        default = 30\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--output_dir',\n",
    "        help = 'GCS location to write checkpoints and export models.',\n",
    "        required = True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--job-dir',\n",
    "        help = 'this model ignores this field, but it is required by gcloud',\n",
    "        default = 'junk'\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    arguments = args.__dict__\n",
    "\n",
    "    # Unused args provided by service\n",
    "    arguments.pop('job_dir', None)\n",
    "    arguments.pop('job-dir', None)\n",
    "\n",
    "    # Append trial_id to path if we are doing hptuning\n",
    "    # This code can be removed if you are not using hyperparameter tuning\n",
    "    arguments['output_dir'] = os.path.join(\n",
    "        arguments['output_dir'],\n",
    "        json.loads(\n",
    "            os.environ.get('TF_CONFIG', '{}')\n",
    "        ).get('task', {}).get('trial', '')\n",
    "    )\n",
    "\n",
    "    # Run the training\n",
    "    shutil.rmtree(arguments['output_dir'], ignore_errors=True) # start fresh each time\n",
    "\n",
    "    # Pass the command line arguments to our model's train_and_evaluate function\n",
    "    model.train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cylinder_prediction_module/trainer/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile cylinder_prediction_module/trainer/model.py\n",
    "import google.datalab.storage as storage\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Read cylinder CSVs from bucket\n",
    "traindf = pd.read_csv('cylinders_train.csv')\n",
    "evaldf = pd.read_csv('cylinders_eval.csv')\n",
    "\n",
    "# Train and eval input functions\n",
    "def train_input_fn(df, batch_size):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x = traindf,\n",
    "        y = traindf['volume'],\n",
    "        num_epochs = None,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True)\n",
    "\n",
    "def eval_input_fn(df, batch_size):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x = evaldf,\n",
    "        y = evaldf['volume'],\n",
    "        num_epochs = 1,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = False)\n",
    "\n",
    "# Define feature columns\n",
    "features = [\n",
    "    tf.feature_column.numeric_column(key='radius', dtype=tf.float64),\n",
    "    tf.feature_column.numeric_column(key='height', dtype=tf.float64)]\n",
    "\n",
    "def train_and_evaluate(args):\n",
    "    # Compute appropriate number of steps.\n",
    "    num_steps = (len(traindf) / args['batch_size']) / args['learning_rate']\n",
    "    # Thus, if learning_rate = 0.01, hundred epochs\n",
    "\n",
    "    # Create custom optimizer\n",
    "    myopt = tf.train.FtrlOptimizer(learning_rate=args['learning_rate'])\n",
    "\n",
    "    # Create rest of the estimator as usual\n",
    "    estimator = tf.estimator.LinearRegressor(\n",
    "        model_dir = args['output_dir'], \n",
    "        feature_columns = features, \n",
    "        optimizer = myopt)\n",
    "    \n",
    "    #Add rmse evaluation metric\n",
    "    def rmse(labels, predictions):\n",
    "        pred_values = tf.cast(predictions['predictions'], tf.float64)\n",
    "        return {'rmse': tf.metrics.root_mean_squared_error(labels, pred_values)}\n",
    "\n",
    "    estimator = tf.contrib.estimator.add_metrics(estimator, rmse)\n",
    "\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn = train_input_fn(df = traindf, batch_size = args['batch_size']),\n",
    "        max_steps = num_steps)\n",
    "\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn = eval_input_fn(df = evaldf, batch_size = len(evaldf)),\n",
    "        steps = None)\n",
    "\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring with TensorBoard\n",
    "Use \"refresh\" in Tensorboard during training to see progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 4985. Click <a href=\"/_proxy/58589/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4985"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "OUTDIR = './cylinders_trained'\n",
    "TensorBoard().start(OUTDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shut TensorBoard down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped TensorBoard with pid 4985\n"
     ]
    }
   ],
   "source": [
    "pids_df = TensorBoard.list()\n",
    "if not pids_df.empty:\n",
    "    for pid in pids_df['pid']:\n",
    "        TensorBoard().stop(pid)\n",
    "        print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model locally to see if everything works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:TF_CONFIG environment variable: {'cluster': {}, 'job': {'job_name': 'trainer.task', 'args': ['--batch_size=30', '--learning_rate=0.02', '--output_dir=cylinders_trained', '--job-dir', 'cylinders_trained']}, 'task': {}, 'environment': 'cloud'}\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_log_step_count_steps': 100, '_save_summary_steps': 100, '_service': None, '_model_dir': 'cylinders_trained/', '_session_config': None, '_train_distribute': None, '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_task_type': 'worker', '_num_worker_replicas': 1, '_save_checkpoints_secs': 600, '_keep_checkpoint_max': 5, '_task_id': 0, '_num_ps_replicas': 0, '_evaluation_master': '', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe07e2ee668>, '_save_checkpoints_steps': None, '_tf_random_seed': None, '_master': ''}\n",
      "INFO:tensorflow:Using config: {'_log_step_count_steps': 100, '_session_config': None, '_service': None, '_model_dir': 'cylinders_trained/', '_save_summary_steps': 100, '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker', '_num_worker_replicas': 1, '_save_checkpoints_secs': 600, '_keep_checkpoint_max': 5, '_task_id': 0, '_num_ps_replicas': 0, '_evaluation_master': '', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe09a7c8ac8>, '_save_checkpoints_steps': None, '_tf_random_seed': None, '_master': ''}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into cylinders_trained/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 2878.79\n",
      "INFO:tensorflow:global_step/sec: 518.757\n",
      "INFO:tensorflow:step = 101, loss = 2090.8699 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.462\n",
      "INFO:tensorflow:step = 201, loss = 1895.4275 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 612.195\n",
      "INFO:tensorflow:step = 301, loss = 1038.4739 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 597.647\n",
      "INFO:tensorflow:step = 401, loss = 1277.864 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 591.019\n",
      "INFO:tensorflow:step = 501, loss = 1661.8907 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.144\n",
      "INFO:tensorflow:step = 601, loss = 545.5654 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 569.815\n",
      "INFO:tensorflow:step = 701, loss = 1437.7838 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 620.367\n",
      "INFO:tensorflow:step = 801, loss = 1120.7251 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.599\n",
      "INFO:tensorflow:step = 901, loss = 993.14087 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 611.056\n",
      "INFO:tensorflow:step = 1001, loss = 965.7406 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.322\n",
      "INFO:tensorflow:step = 1101, loss = 842.1328 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 583.975\n",
      "INFO:tensorflow:step = 1201, loss = 602.4868 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 557.887\n",
      "INFO:tensorflow:step = 1301, loss = 1096.1799 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 613.91\n",
      "INFO:tensorflow:step = 1401, loss = 1096.4951 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.531\n",
      "INFO:tensorflow:step = 1501, loss = 841.614 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 584.131\n",
      "INFO:tensorflow:step = 1601, loss = 699.9575 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 615.533\n",
      "INFO:tensorflow:step = 1701, loss = 1438.0691 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.54\n",
      "INFO:tensorflow:step = 1801, loss = 321.87936 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 613.05\n",
      "INFO:tensorflow:step = 1901, loss = 390.50815 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.851\n",
      "INFO:tensorflow:step = 2001, loss = 548.12646 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 615.652\n",
      "INFO:tensorflow:step = 2101, loss = 811.25867 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.071\n",
      "INFO:tensorflow:step = 2201, loss = 822.3984 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 627.192\n",
      "INFO:tensorflow:step = 2301, loss = 616.5349 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.98\n",
      "INFO:tensorflow:step = 2401, loss = 802.381 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.127\n",
      "INFO:tensorflow:step = 2501, loss = 659.87506 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 601.317\n",
      "INFO:tensorflow:step = 2601, loss = 742.0033 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 588.183\n",
      "INFO:tensorflow:step = 2701, loss = 761.7134 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 572.744\n",
      "INFO:tensorflow:step = 2801, loss = 794.87115 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.227\n",
      "INFO:tensorflow:step = 2901, loss = 510.57745 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.113\n",
      "INFO:tensorflow:step = 3001, loss = 362.1754 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 592.805\n",
      "INFO:tensorflow:step = 3101, loss = 703.68304 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.419\n",
      "INFO:tensorflow:step = 3201, loss = 412.01694 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 581.337\n",
      "INFO:tensorflow:step = 3301, loss = 373.638 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 590.835\n",
      "INFO:tensorflow:step = 3401, loss = 692.1817 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 600.798\n",
      "INFO:tensorflow:step = 3501, loss = 556.83795 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 605.174\n",
      "INFO:tensorflow:step = 3601, loss = 679.78564 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 587.095\n",
      "INFO:tensorflow:step = 3701, loss = 626.37274 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 584.101\n",
      "INFO:tensorflow:step = 3801, loss = 462.31082 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 605.092\n",
      "INFO:tensorflow:step = 3901, loss = 991.881 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 604.548\n",
      "INFO:tensorflow:step = 4001, loss = 394.19348 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 598.105\n",
      "INFO:tensorflow:step = 4101, loss = 351.78052 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 593.255\n",
      "INFO:tensorflow:step = 4201, loss = 275.73453 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 587.134\n",
      "INFO:tensorflow:step = 4301, loss = 342.89532 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 593.493\n",
      "INFO:tensorflow:step = 4401, loss = 915.5723 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 599.37\n",
      "INFO:tensorflow:step = 4501, loss = 370.17825 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 589.789\n",
      "INFO:tensorflow:step = 4601, loss = 789.6085 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 601.77\n",
      "INFO:tensorflow:step = 4701, loss = 608.04944 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 601.047\n",
      "INFO:tensorflow:step = 4801, loss = 359.51678 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.37\n",
      "INFO:tensorflow:step = 4901, loss = 610.51355 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 605.371\n",
      "INFO:tensorflow:step = 5001, loss = 472.3694 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 604.915\n",
      "INFO:tensorflow:step = 5101, loss = 303.97772 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 603.268\n",
      "INFO:tensorflow:step = 5201, loss = 684.8888 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 567.239\n",
      "INFO:tensorflow:step = 5301, loss = 409.4381 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 574.622\n",
      "INFO:tensorflow:step = 5401, loss = 263.4721 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 565.161\n",
      "INFO:tensorflow:step = 5501, loss = 482.3619 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.756\n",
      "INFO:tensorflow:step = 5601, loss = 620.8367 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.018\n",
      "INFO:tensorflow:step = 5701, loss = 468.06458 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 590.834\n",
      "INFO:tensorflow:step = 5801, loss = 504.7974 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 618.567\n",
      "INFO:tensorflow:step = 5901, loss = 329.47888 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 626.579\n",
      "INFO:tensorflow:step = 6001, loss = 461.95294 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 543.579\n",
      "INFO:tensorflow:step = 6101, loss = 352.42584 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.483\n",
      "INFO:tensorflow:step = 6201, loss = 643.59515 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.916\n",
      "INFO:tensorflow:step = 6301, loss = 395.19705 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 604.743\n",
      "INFO:tensorflow:step = 6401, loss = 372.52673 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.507\n",
      "INFO:tensorflow:step = 6501, loss = 382.00378 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.413\n",
      "INFO:tensorflow:step = 6601, loss = 385.94836 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 593.115\n",
      "INFO:tensorflow:step = 6701, loss = 658.0305 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.444\n",
      "INFO:tensorflow:step = 6801, loss = 642.707 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 609.103\n",
      "INFO:tensorflow:step = 6901, loss = 303.83792 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 600.195\n",
      "INFO:tensorflow:step = 7001, loss = 586.33276 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.726\n",
      "INFO:tensorflow:step = 7101, loss = 507.73822 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.806\n",
      "INFO:tensorflow:step = 7201, loss = 652.08936 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.782\n",
      "INFO:tensorflow:step = 7301, loss = 583.36426 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.041\n",
      "INFO:tensorflow:step = 7401, loss = 498.96606 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.502\n",
      "INFO:tensorflow:step = 7501, loss = 244.70796 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.23\n",
      "INFO:tensorflow:step = 7601, loss = 372.5595 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 630.66\n",
      "INFO:tensorflow:step = 7701, loss = 409.35336 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.12\n",
      "INFO:tensorflow:step = 7801, loss = 541.7534 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.658\n",
      "INFO:tensorflow:step = 7901, loss = 465.00116 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 612.97\n",
      "INFO:tensorflow:step = 8001, loss = 285.92722 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 626.261\n",
      "INFO:tensorflow:step = 8101, loss = 340.77448 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 627.507\n",
      "INFO:tensorflow:step = 8201, loss = 475.98334 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 636.285\n",
      "INFO:tensorflow:step = 8301, loss = 293.75812 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 636.156\n",
      "INFO:tensorflow:step = 8401, loss = 367.19867 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 633.799\n",
      "INFO:tensorflow:step = 8501, loss = 492.47537 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 607.577\n",
      "INFO:tensorflow:step = 8601, loss = 320.74783 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 634.634\n",
      "INFO:tensorflow:step = 8701, loss = 340.24738 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 634.084\n",
      "INFO:tensorflow:step = 8801, loss = 332.49603 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.73\n",
      "INFO:tensorflow:step = 8901, loss = 769.2326 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 620.56\n",
      "INFO:tensorflow:step = 9001, loss = 596.2777 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 592.53\n",
      "INFO:tensorflow:step = 9101, loss = 516.52606 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 577.311\n",
      "INFO:tensorflow:step = 9201, loss = 429.59915 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 613.255\n",
      "INFO:tensorflow:step = 9301, loss = 664.4059 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.075\n",
      "INFO:tensorflow:step = 9401, loss = 338.33075 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 578.179\n",
      "INFO:tensorflow:step = 9501, loss = 401.82632 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.779\n",
      "INFO:tensorflow:step = 9601, loss = 722.17035 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 583.483\n",
      "INFO:tensorflow:step = 9701, loss = 397.80664 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 570.985\n",
      "INFO:tensorflow:step = 9801, loss = 357.8857 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 608.001\n",
      "INFO:tensorflow:step = 9901, loss = 664.5833 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.795\n",
      "INFO:tensorflow:step = 10001, loss = 596.16364 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 624.504\n",
      "INFO:tensorflow:step = 10101, loss = 505.94006 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 625.391\n",
      "INFO:tensorflow:step = 10201, loss = 338.98935 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 609.216\n",
      "INFO:tensorflow:step = 10301, loss = 450.74005 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 592.032\n",
      "INFO:tensorflow:step = 10401, loss = 196.8393 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.374\n",
      "INFO:tensorflow:step = 10501, loss = 364.72754 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 609.034\n",
      "INFO:tensorflow:step = 10601, loss = 553.65326 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 604.201\n",
      "INFO:tensorflow:step = 10701, loss = 321.88422 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 592.921\n",
      "INFO:tensorflow:step = 10801, loss = 332.4175 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 619.779\n",
      "INFO:tensorflow:step = 10901, loss = 534.5059 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.82\n",
      "INFO:tensorflow:step = 11001, loss = 540.2191 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 603.033\n",
      "INFO:tensorflow:step = 11101, loss = 399.057 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 600.735\n",
      "INFO:tensorflow:step = 11201, loss = 272.90018 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 599.787\n",
      "INFO:tensorflow:step = 11301, loss = 241.96123 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 597.558\n",
      "INFO:tensorflow:step = 11401, loss = 412.99585 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 613.506\n",
      "INFO:tensorflow:step = 11501, loss = 333.0876 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 603.732\n",
      "INFO:tensorflow:step = 11601, loss = 386.54724 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 615.952\n",
      "INFO:tensorflow:step = 11701, loss = 737.042 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.432\n",
      "INFO:tensorflow:step = 11801, loss = 589.19214 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 607.485\n",
      "INFO:tensorflow:step = 11901, loss = 394.02844 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.632\n",
      "INFO:tensorflow:step = 12001, loss = 588.6764 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 547.614\n",
      "INFO:tensorflow:step = 12101, loss = 571.4637 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 589.383\n",
      "INFO:tensorflow:step = 12201, loss = 618.51996 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 621\n",
      "INFO:tensorflow:step = 12301, loss = 432.60925 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 598.751\n",
      "INFO:tensorflow:step = 12401, loss = 500.60522 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.52\n",
      "INFO:tensorflow:step = 12501, loss = 403.25928 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 612.119\n",
      "INFO:tensorflow:step = 12601, loss = 287.24023 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 618.188\n",
      "INFO:tensorflow:step = 12701, loss = 640.46375 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 599.199\n",
      "INFO:tensorflow:step = 12801, loss = 305.53342 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 607.085\n",
      "INFO:tensorflow:step = 12901, loss = 357.49036 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 608.833\n",
      "INFO:tensorflow:step = 13001, loss = 549.8187 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 601.417\n",
      "INFO:tensorflow:step = 13101, loss = 366.5483 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 612.032\n",
      "INFO:tensorflow:step = 13201, loss = 484.71335 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 619.7\n",
      "INFO:tensorflow:step = 13301, loss = 671.7093 (0.161 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13334 into cylinders_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 575.04816.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-14-13:19:45\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from cylinders_trained/model.ckpt-13334\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-14-13:19:45\n",
      "INFO:tensorflow:Saving dict for global step 13334: average_loss = 16.08314, global_step = 13334, loss = 16083.139, rmse = 4.010379\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf cylinders_trained\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/cylinder_prediction_module\n",
    "gcloud ml-engine local train \\\n",
    "    --module-name=trainer.task \\\n",
    "    --job-dir=cylinders_trained \\\n",
    "    --package-path=$(pwd)/trainer \\\n",
    "    -- \\\n",
    "    --batch_size=30 \\\n",
    "    --learning_rate=0.02 \\\n",
    "    --output_dir=cylinders_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hyperparam.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hyperparam.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyperparam.yaml\n",
    "trainingInput:\n",
    "    hyperparameters:\n",
    "        goal: MINIMIZE\n",
    "        maxTrials: 16\n",
    "        maxParallelTrials: 2\n",
    "        hyperparameterMetricTag: rmse\n",
    "        params:\n",
    "        - parameterName: batch_size\n",
    "          type: INTEGER\n",
    "          minValue: 8\n",
    "          maxValue: 64\n",
    "          scaleType: UNIT_LINEAR_SCALE\n",
    "        - parameterName: learning_rate\n",
    "          type: DOUBLE\n",
    "          minValue: 0.01\n",
    "          maxValue: 0.1\n",
    "          scaleType: UNIT_LOG_SCALE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the hyperparameter tuning job to Cloud ML Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: cylinders_190314_133749\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://cylinders/cylinders_trained/packages/b1b5b353b930eabdda02a904c7db491433eda70f05f4286af4c78b738f72dc8d/trainer-0.0.0.tar.gz#1552570494328430...\n",
      "/ [1 objects]                                                                   \r\n",
      "Operation completed over 1 objects.                                              \n",
      "Job [cylinders_190314_133749] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe cylinders_190314_133749\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs cylinders_190314_133749\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/cylinders_trained   # CHANGE bucket name appropriately\n",
    "gsutil rm -rf $OUTDIR\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/cylinder_prediction_module\n",
    "gcloud ml-engine jobs submit training cylinders_$(date -u +%y%m%d_%H%M%S) \\\n",
    "    --config=hyperparam.yaml \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=$(pwd)/cylinder_prediction_module/trainer \\\n",
    "    --job-dir=$OUTDIR \\\n",
    "    --runtime-version=$TFVERSION \\\n",
    "    --\\\n",
    "    --output_dir=$OUTDIR \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2019-03-14T13:37:52Z'\n",
      "etag: X6m_anszLjA=\n",
      "jobId: cylinders_190314_133749\n",
      "startTime: '2019-03-14T13:37:55Z'\n",
      "state: RUNNING\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --output_dir=gs://cylinders/cylinders_trained\n",
      "  hyperparameters:\n",
      "    goal: MINIMIZE\n",
      "    hyperparameterMetricTag: rmse\n",
      "    maxParallelTrials: 2\n",
      "    maxTrials: 16\n",
      "    params:\n",
      "    - maxValue: 64.0\n",
      "      minValue: 8.0\n",
      "      parameterName: batch_size\n",
      "      scaleType: UNIT_LINEAR_SCALE\n",
      "      type: INTEGER\n",
      "    - maxValue: 0.1\n",
      "      minValue: 0.01\n",
      "      parameterName: learning_rate\n",
      "      scaleType: UNIT_LOG_SCALE\n",
      "      type: DOUBLE\n",
      "  jobDir: gs://cylinders/cylinders_trained\n",
      "  packageUris:\n",
      "  - gs://cylinders/cylinders_trained/packages/77e32208113769baa0952b8a4950a8e090ff2b5d850704214e3388beb06e9b63/trainer-0.0.0.tar.gz\n",
      "  pythonModule: trainer.task\n",
      "  region: europe-west1\n",
      "  runtimeVersion: '1.8'\n",
      "trainingOutput:\n",
      "  isHyperparameterTuningJob: true\n",
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/ml/jobs/cylinders_190314_133749?project=cylinders\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2Fcylinders_190314_133749&project=cylinders\n",
      "\n",
      "\n",
      "Updates are available for some Cloud SDK components.  To install them,\n",
      "please run:\n",
      "  $ gcloud components update\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine jobs describe cylinders_190314_133749  # Change jobId to what the previous cell output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
