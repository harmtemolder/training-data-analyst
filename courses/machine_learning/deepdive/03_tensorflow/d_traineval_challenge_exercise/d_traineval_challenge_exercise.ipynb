{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Exercise\n",
    "\n",
    "Create a neural network that is capable of finding the volume of a cylinder given the radius of its base (r) and its height (h). Assume that the radius and height of the cylinder are both in the range 0.5 to 2.0. Unlike in the challenge exercise for b_estimator.ipynb, assume that your measurements of r, h and V are all rounded off to the nearest 0.1. Simulate the necessary training dataset. This time, you will need a lot more data to get a good predictor.\n",
    "<p>\n",
    "Now modify the \"noise\" so that instead of just rounding off the value, there is up to a 10% error (uniformly distributed) in the measurement followed by rounding off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "from math import pi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cylinders(filename, size):\n",
    "  \"\"\"Generate a dataframe of cylinders where the radius and height of\n",
    "  each cylinder are both in the range 0.5 to 2.0 and the volume equals\n",
    "  (pi * r^2) * h. Then add up to a 10% error (uniformly distributed) to\n",
    "  the volume, followed by rounding off radius, height and volume to the\n",
    "  nearest 0.1. Then write that dataframe to a CSV file.\n",
    "  \"\"\"\n",
    "  \n",
    "  # Generate radiuses and heights\n",
    "  radius = np.random.uniform(0.5, 2.0, size=size)\n",
    "  height = np.random.uniform(0.5, 2.0, size=size)\n",
    "  \n",
    "  # Calculate the correct volumes with those radiuses and heights\n",
    "  volume = (pi * radius ** 2) * height\n",
    "  \n",
    "  # Add the error to the volumes\n",
    "  volume = volume * np.random.uniform(0.9, 1.1, size=size)\n",
    "  \n",
    "  # Then round off radius, height and volume\n",
    "  radius = np.round(radius, decimals=1)\n",
    "  height = np.round(height, decimals=1)\n",
    "  volume = np.round(volume, decimals=1)\n",
    "  \n",
    "  df = pd.DataFrame({\n",
    "    'volume': volume,\n",
    "    'radius': radius,\n",
    "    'height': height,\n",
    "  })\n",
    "  \n",
    "  df.to_csv(filename, header=False, index=False)\n",
    "  print('wrote {} cylinders to {}'.format(size, filename))\n",
    "\n",
    "total_size = 10 ** 7\n",
    "\n",
    "generate_cylinders('cylinders-train.csv', int(0.8 * total_size))\n",
    "generate_cylinders('cylinders-valid.csv', int(0.1 * total_size))\n",
    "generate_cylinders('cylinders-test.csv', int(0.1 * total_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMNS = ['volume', 'radius','height']\n",
    "LABEL_COLUMN = 'volume'\n",
    "DEFAULTS = [[25.1], [2.0], [2.0]]\n",
    "\n",
    "def read_dataset(filename, mode, batch_size = 1024):\n",
    "      def decode_csv(value_column):\n",
    "          \"\"\"Read a single line of CSV and return a tuple (features, label), where\n",
    "          * features is a dict of radius and height,\n",
    "          * and label is a dict of volume.\n",
    "          \"\"\"\n",
    "          columns = tf.decode_csv(value_column, record_defaults = DEFAULTS)\n",
    "          features = dict(zip(CSV_COLUMNS, columns))\n",
    "          label = features.pop(LABEL_COLUMN)\n",
    "\n",
    "          return features, label\n",
    "\n",
    "      # Create list of file names that match \"glob\" pattern (i.e. data_file_*.csv)\n",
    "      filenames_dataset = tf.data.Dataset.list_files(filename)\n",
    "      \n",
    "      # Read lines from text files\n",
    "      textlines_dataset = filenames_dataset.flat_map(tf.data.TextLineDataset)\n",
    "      \n",
    "      # Parse text lines as comma-separated values (CSV)\n",
    "      dataset = textlines_dataset.map(decode_csv)\n",
    "\n",
    "      # Note:\n",
    "      # use tf.data.Dataset.flat_map to apply one to many transformations (here: filename -> text lines)\n",
    "      # use tf.data.Dataset.map      to apply one to one  transformations (here: text line -> feature list)\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "          num_epochs = None # indefinitely\n",
    "          dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "      else:\n",
    "          num_epochs = 1 # end-of-input after this\n",
    "\n",
    "      dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "      \n",
    "      return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create features out of input data\n",
    "For now, pass these through.  (same as previous lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_COLUMNS = [\n",
    "    tf.feature_column.numeric_column('radius'),\n",
    "    tf.feature_column.numeric_column('height'),\n",
    "]\n",
    "\n",
    "def add_more_features(feats):\n",
    "    # Nothing to add (yet!)\n",
    "    return feats\n",
    "\n",
    "feature_cols = add_more_features(INPUT_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    \"\"\"Defines the expected shape of the JSON feed that the model\n",
    "    will receive once deployed behind a REST API in production.\n",
    "    \"\"\"\n",
    "\n",
    "    json_feature_placeholders = {\n",
    "        'radius' : tf.placeholder(tf.float32, [None]),\n",
    "        'height' : tf.placeholder(tf.float32, [None]),\n",
    "    }\n",
    "    \n",
    "    # You can transform data here from the input format to the format expected by your model.\n",
    "    features = json_feature_placeholders # no transformation needed\n",
    "    \n",
    "    return tf.estimator.export.ServingInputReceiver(features, json_feature_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.estimator.train_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "    estimator = tf.estimator.DNNRegressor(\n",
    "                        hidden_units=[128, 64, 32, 16],\n",
    "                        model_dir = output_dir,\n",
    "                        feature_columns = feature_cols)\n",
    "    \n",
    "    train_spec=tf.estimator.TrainSpec(\n",
    "                       input_fn = lambda: read_dataset('./cylinders-train.csv', mode = tf.estimator.ModeKeys.TRAIN),\n",
    "                       max_steps = num_train_steps)\n",
    "\n",
    "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "\n",
    "    eval_spec=tf.estimator.EvalSpec(\n",
    "                       input_fn = lambda: read_dataset('./cylinders-valid.csv', mode = tf.estimator.ModeKeys.EVAL),\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 1, # start evaluating after N seconds\n",
    "                       throttle_secs = 10,  # evaluate every N seconds\n",
    "                       exporters = exporter)\n",
    "    \n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring with TensorBoard\n",
    "Use \"refresh\" in Tensorboard during training to see progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = './cylinders_trained'\n",
    "TensorBoard().start(OUTDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training    \n",
    "shutil.rmtree(OUTDIR, ignore_errors = True)  # start fresh each time\n",
    "tf.summary.FileWriterCache.clear()  # ensure filewriter cache is clear for TensorBoard events file\n",
    "train_and_evaluate(OUTDIR, num_train_steps = 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can now shut Tensorboard down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pids_df = TensorBoard.list()\n",
    "if not pids_df.empty:\n",
    "    for pid in pids_df['pid']:\n",
    "        TensorBoard().stop(pid)\n",
    "        print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
